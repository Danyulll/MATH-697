# MRMES <- c()
# for (i in 1:100) {
#   cat("iter: ",i,"\n")
#   set.seed(i+100)
#   MRME.out <-lasso_cox(N = 100, n = 100)$MRME_LASSO
#   MRMES <- c(MRMES, MRME.out)
# }
#
# max(MRMES)
#
# plot(density(MRMES))
set.seed(100)
lasso_cox(N = 100, n = 100)$MRME_LASSO
set.seed(101)
lasso_cox(N = 100, n = 100)$MRME_LASSO
library(parallel)
# Define the number of cores to use
num_cores <- detectCores() - 1  # Adjust based on your system; this uses all but one core
# Define the function to run each iteration
run_iteration <- function(i) {
cat("iter: ", i, "\n")
set.seed(i + 100)
MRME.out <- lasso_cox(N = 100, n = 100)$MRME_LASSO
return(MRME.out)
}
# Run the loop in parallel
MRMES <- mclapply(1:500, run_iteration, mc.cores = num_cores)
# Load required libraries
library(foreach)
library(doParallel)
# Set up parallel backend to use multiple cores
num_cores <- detectCores() - 1  # Number of cores to use
cl <- makeCluster(num_cores)    # Create the cluster
registerDoParallel(cl)          # Register the parallel backend
# Run the loop in parallel
MRMES <- foreach(i = 1:500, .combine = c) %dopar% {
set.seed(i + 100)
lasso_cox(N = 100, n = 100)$MRME_LASSO
}
# Load required libraries
library(foreach)
library(doParallel)
library(MASS)  # Load in main environment for consistency
# Set up parallel backend to use multiple cores
num_cores <- detectCores() - 1  # Number of cores to use
cl <- makeCluster(num_cores)    # Create the cluster
registerDoParallel(cl)          # Register the parallel backend
# Run the loop in parallel
MRMES <- foreach(i = 1:500, .combine = c, .packages = c("MASS", "survival", "glmnet")) %dopar% {
set.seed(i + 100)
lasso_cox(N = 100, n = 100)$MRME_LASSO
}
# Stop the cluster after computation is complete
stopCluster(cl)
# Print or analyze MRMES as needed
print(MRMES)
max(MRMES)
plot(density(MRMES))
which.max(MRMES)
1:500 + 100
(1:500 + 100)[103]
set.seed(203)
lasso_cox(N = 100, n = 100)
library(survival)
library(glmnet)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt"))])
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = pbc)
# Extract and display the summary table with kable
cox_summary_all <- summary(cox_model_all)$coefficients
kable(cox_summary_all, caption = "Cox Proportional Hazards Model Summary with All Covariates")
library(survival)
library(glmnet)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt"))])
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = as.data.frame(x))
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt"))]
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
library(survival)
library(glmnet)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt"))]
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
# Extract and display the summary table with kable
cox_summary_all <- summary(cox_model_all)$coefficients
kable(cox_summary_all, caption = "Cox Proportional Hazards Model Summary with All Covariates")
data("pbc", package = "survival")
library(kableExtra)
library(survival)
library(glmnet)
library(kableExtra)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
# Extract and modify the summary table
cox_summary_all <- summary(cox_model_all)$coefficients
cox_summary_all <- as.data.frame(cox_summary_all)
# Define the significance level
alpha <- 0.05
# Format p-values: Bold if p-value is below alpha
cox_summary_all$p_value <- ifelse(cox_summary_all[, "Pr(>|z|)"] < alpha,
paste0("**", formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2), "**"),
formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2))
# Display the table with kableExtra
cox_summary_all %>%
kable(caption = "Cox Proportional Hazards Model Summary with All Covariates", format = "html") %>%
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
library(survival)
library(glmnet)
library(kableExtra)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
# Extract and modify the summary table
cox_summary_all <- summary(cox_model_all)$coefficients
cox_summary_all <- as.data.frame(cox_summary_all)
# Define the significance level
alpha <- 0.05
# Format p-values: Bold if p-value is below alpha
cox_summary_all$p_value <- ifelse(cox_summary_all[, "Pr(>|z|)"] < alpha,
paste0("\\textbf{", formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2), "}"),
formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2))
# Select and format the table for PDF output
cox_summary_all %>%
dplyr::select(-`Pr(>|z|)`, everything()) %>%  # Reorder to remove original p-values
kable("latex", booktabs = TRUE, escape = FALSE, caption = "Cox Proportional Hazards Model Summary with All Covariates") %>%
kable_styling()
# Define the outcome as a Surv object for time-to-event analysis
y <- Surv(pbc$time, pbc$status == 2)  # status == 2 indicates death
# Get the predictor names (excluding time, status, and id)
predictor_names <- names(pbc)[!(names(pbc) %in% c("time", "status", "id","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Generate all possible combinations of predictors
combinations <- unlist(lapply(1:length(predictor_names), function(x) {
combn(predictor_names, x, simplify = FALSE)
}), recursive = FALSE)
# Create a cluster for parallel processing using 15 cores
num_cores <- 15
cl <- makeCluster(num_cores)
clusterEvalQ(cl, library(survival))  # Load necessary libraries on each node
clusterExport(cl, c("pbc", "y", "combinations"))  # Export data and combinations to cluster nodes
# Define a function to fit a model and calculate AIC and BIC
fit_model <- function(predictors) {
formula <- as.formula(paste("y ~", paste(predictors, collapse = " + ")))
model <- coxph(formula, data = pbc)
aic <- AIC(model)
bic <- BIC(model)
return(list(model = model, AIC = aic, BIC = bic))
}
# Run the model fitting in parallel across all combinations
results <- parLapply(cl, combinations, fit_model)
save(results,file = "AIC_BIC_app.RData")
load("AIC_BIC_app.RData")
# Stop the cluster after the operation
stopCluster(cl)
# Extract the best models based on AIC and BIC
aic_values <- sapply(results, function(x) x$AIC)
bic_values <- sapply(results, function(x) x$BIC)
best_model_AIC <- results[[which.min(aic_values)]]$model
best_model_BIC <- results[[which.min(bic_values)]]$model
best_model_AIC
best_model_BIC
# Load necessary libraries
# Define the outcome as a Surv object for time-to-event analysis
y <- Surv(pbc$time, pbc$status == 2)  # status == 2 indicates death
# Get the predictor names (excluding time, status, and id)
predictor_names <- names(pbc)[!(names(pbc) %in% c("time", "status", "id","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Generate all possible combinations of predictors
combinations <- unlist(lapply(1:length(predictor_names), function(x) {
combn(predictor_names, x, simplify = FALSE)
}), recursive = FALSE)
# Create a cluster for parallel processing using 15 cores
num_cores <- 15
cl <- makeCluster(num_cores)
clusterEvalQ(cl, library(survival))  # Load necessary libraries on each node
clusterExport(cl, c("pbc", "y", "combinations"))  # Export data and combinations to cluster nodes
# Define a function to fit a model and calculate AIC and BIC
fit_model <- function(predictors) {
formula <- as.formula(paste("y ~", paste(predictors, collapse = " + ")))
model <- coxph(formula, data = pbc)
aic <- AIC(model)
bic <- BIC(model)
return(list(model = model, AIC = aic, BIC = bic))
}
# Run the model fitting in parallel across all combinations
results <- parLapply(cl, combinations, fit_model)
stopCluster(cl)
# Extract the best models based on AIC and BIC
aic_values <- sapply(results, function(x) x$AIC)
bic_values <- sapply(results, function(x) x$BIC)
best_model_AIC <- results[[which.min(aic_values)]]$model
best_model_BIC <- results[[which.min(bic_values)]]$model
save(best_model_AIC,file="best_model_AIC.RData")
save(best_model_BIC,file="best_model_BIC.RData")
load("best_model_AIC.RData")
load("best_model_BIC.RData")
# coef(final_lasso_cox)
# coef(scad_cox_path, lambda = best_lambda_scad)
# best_model_AIC |> coef()
# best_model_BIC |> coef()
coef_lasso <- as.vector(coef(final_lasso_cox))
names(coef_lasso) <- rownames(coef(final_lasso_cox))  # Set rownames explicitly for the LASSO coefficients
coef_scad_matrix <- coef(scad_cox_path, lambda = best_lambda_scad)
library(survival)
library(glmnet)
library(kableExtra)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
# Extract and modify the summary table
cox_summary_all <- summary(cox_model_all)$coefficients
cox_summary_all <- as.data.frame(cox_summary_all)
# Define the significance level
alpha <- 0.05
# Format p-values: Bold if p-value is below alpha
cox_summary_all$p_value <- ifelse(cox_summary_all[, "Pr(>|z|)"] < alpha,
paste0("**", formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2), "**"),
formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2))
# Display the table with kableExtra
cox_summary_all %>%
kable(caption = "Cox Proportional Hazards Model Summary with All Covariates", format = "html") %>%
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
library(ncvreg)
scad_cox_path <- ncvsurv(x, y, penalty = "SCAD")
cv_scad_cox <- cv.ncvsurv(x, y, penalty = "SCAD")
best_lambda_scad <- cv_scad_cox$lambda.min
# Load necessary libraries
# Define the outcome as a Surv object for time-to-event analysis
y <- Surv(pbc$time, pbc$status == 2)  # status == 2 indicates death
# Get the predictor names (excluding time, status, and id)
predictor_names <- names(pbc)[!(names(pbc) %in% c("time", "status", "id","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Generate all possible combinations of predictors
combinations <- unlist(lapply(1:length(predictor_names), function(x) {
combn(predictor_names, x, simplify = FALSE)
}), recursive = FALSE)
# Create a cluster for parallel processing using 15 cores
num_cores <- 15
cl <- makeCluster(num_cores)
clusterEvalQ(cl, library(survival))  # Load necessary libraries on each node
clusterExport(cl, c("pbc", "y", "combinations"))  # Export data and combinations to cluster nodes
# Define a function to fit a model and calculate AIC and BIC
fit_model <- function(predictors) {
formula <- as.formula(paste("y ~", paste(predictors, collapse = " + ")))
model <- coxph(formula, data = pbc)
aic <- AIC(model)
bic <- BIC(model)
return(list(model = model, AIC = aic, BIC = bic))
}
# Run the model fitting in parallel across all combinations
results <- parLapply(cl, combinations, fit_model)
stopCluster(cl)
# Extract the best models based on AIC and BIC
aic_values <- sapply(results, function(x) x$AIC)
bic_values <- sapply(results, function(x) x$BIC)
best_model_AIC <- results[[which.min(aic_values)]]$model
best_model_BIC <- results[[which.min(bic_values)]]$model
save(best_model_AIC,file="best_model_AIC.RData")
save(best_model_BIC,file="best_model_BIC.RData")
load("best_model_AIC.RData")
load("best_model_BIC.RData")
# coef(final_lasso_cox)
# coef(scad_cox_path, lambda = best_lambda_scad)
# best_model_AIC |> coef()
# best_model_BIC |> coef()
coef_lasso <- as.vector(coef(final_lasso_cox))
names(coef_lasso) <- rownames(coef(final_lasso_cox))  # Set rownames explicitly for the LASSO coefficients
coef_scad_matrix <- coef(scad_cox_path, lambda = best_lambda_scad)
if (is.matrix(coef_scad_matrix)) {
coef_scad <- as.vector(coef_scad_matrix)
names(coef_scad) <- rownames(coef_scad_matrix)
} else {
coef_scad <- coef_scad_matrix
}
coef_aic <- coef(best_model_AIC)
coef_bic <- coef(best_model_BIC)
var_names <- unique(c(names(coef_lasso), names(coef_scad), names(coef_aic), names(coef_bic)))
coef_table <- data.frame(
Method = var_names,
LASSO = rep("-", length(var_names)),
SCAD = rep("-", length(var_names)),
AIC = rep("-", length(var_names)),
BIC = rep("-", length(var_names)),
stringsAsFactors = FALSE
)
rownames(coef_table) <- coef_table$Method
coef_table$Method <- NULL
for (var in var_names) {
if (var %in% names(coef_lasso)) {
coef_table[var, "LASSO"] <- sprintf("%.4f", coef_lasso[var])
}
if (var %in% names(coef_scad)) {
coef_table[var, "SCAD"] <- sprintf("%.4f", coef_scad[var])
}
if (var %in% names(coef_aic)) {
coef_table[var, "AIC"] <- sprintf("%.4f", coef_aic[var])
}
if (var %in% names(coef_bic)) {
coef_table[var, "BIC"] <- sprintf("%.4f", coef_bic[var])
}
}
coef_table[] <- lapply(coef_table, function(col) {
ifelse(col == "0.0000", "-", col)
})
coef_table <- coef_table[order(rowSums(coef_table != "-"), decreasing = TRUE), ]
kable(coef_table,caption = "Coefficient Estimates with Various Estimation Methods")
library(survival)
library(glmnet)
library(kableExtra)
data("pbc", package = "survival")
pbc <- na.omit(pbc)
pbc <- pbc[,-1]
y <- with(pbc, Surv(time, status == 2))  # status == 2 indicates death
x <- data.matrix(pbc[, !(names(pbc) %in% c("time", "status","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))])
x2 <- pbc[, !(names(pbc) %in% c("trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Use cross validation to get best lambda
cv_lasso_cox <- cv.glmnet(x, y, family = "cox", alpha = 1)
best_lambda <- cv_lasso_cox$lambda.min
# Fit optimal model
final_lasso_cox <- glmnet(x, y, family = "cox", alpha = 1, lambda = best_lambda)
# Fit the Cox model with all covariates
cox_model_all <- coxph(Surv(time, status == 2) ~ ., data = x2)
# Extract and modify the summary table
cox_summary_all <- summary(cox_model_all)$coefficients
cox_summary_all <- as.data.frame(cox_summary_all)
# Define the significance level
alpha <- 0.05
# Format p-values: Bold if p-value is below alpha
cox_summary_all$p_value <- ifelse(cox_summary_all[, "Pr(>|z|)"] < alpha,
paste0("**", formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2), "**"),
formatC(cox_summary_all[, "Pr(>|z|)"], format = "e", digits = 2))
# Display the table with kableExtra
kable(cox_summary_all)
y <- Surv(pbc$time, pbc$status == 2)  # status == 2 indicates death
# Get the predictor names (excluding time, status, and id)
predictor_names <- names(pbc)[!(names(pbc) %in% c("time", "status", "id","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
# Generate all possible combinations of predictors
combinations <- unlist(lapply(1:length(predictor_names), function(x) {
combn(predictor_names, x, simplify = FALSE)
}), recursive = FALSE)
# Create a cluster for parallel processing using 15 cores
num_cores <- 15
cl <- makeCluster(num_cores)
clusterEvalQ(cl, library(survival))  # Load necessary libraries on each node
clusterExport(cl, c("pbc", "y", "combinations"))  # Export data and combinations to cluster nodes
# Define a function to fit a model and calculate AIC and BIC
fit_model <- function(predictors) {
formula <- as.formula(paste("y ~", paste(predictors, collapse = " + ")))
model <- coxph(formula, data = pbc)
aic <- AIC(model)
bic <- BIC(model)
return(list(model = model, AIC = aic, BIC = bic))
}
# Run the model fitting in parallel across all combinations
results <- parLapply(cl, combinations, fit_model)
stopCluster(cl)
# Extract the best models based on AIC and BIC
aic_values <- sapply(results, function(x) x$AIC)
bic_values <- sapply(results, function(x) x$BIC)
best_model_AIC <- results[[which.min(aic_values)]]$model
best_model_BIC <- results[[which.min(bic_values)]]$model
save(best_model_AIC,file="best_model_AIC.RData")
save(best_model_BIC,file="best_model_BIC.RData")
best_model_AIC
# Define the outcome as a Surv object for time-to-event analysis
# y <- Surv(pbc$time, pbc$status == 2)  # status == 2 indicates death
#
# # Get the predictor names (excluding time, status, and id)
# predictor_names <- names(pbc)[!(names(pbc) %in% c("time", "status", "id","trig","platelet","alk.phos","spiders","hepato","trt","ascites"))]
#
# # Generate all possible combinations of predictors
# combinations <- unlist(lapply(1:length(predictor_names), function(x) {
#   combn(predictor_names, x, simplify = FALSE)
# }), recursive = FALSE)
#
# # Create a cluster for parallel processing using 15 cores
# num_cores <- 15
# cl <- makeCluster(num_cores)
# clusterEvalQ(cl, library(survival))  # Load necessary libraries on each node
# clusterExport(cl, c("pbc", "y", "combinations"))  # Export data and combinations to cluster nodes
#
# # Define a function to fit a model and calculate AIC and BIC
# fit_model <- function(predictors) {
#   formula <- as.formula(paste("y ~", paste(predictors, collapse = " + ")))
#   model <- coxph(formula, data = pbc)
#   aic <- AIC(model)
#   bic <- BIC(model)
#   return(list(model = model, AIC = aic, BIC = bic))
# }
#
# # Run the model fitting in parallel across all combinations
# results <- parLapply(cl, combinations, fit_model)
#
# stopCluster(cl)
#
# # Extract the best models based on AIC and BIC
# aic_values <- sapply(results, function(x) x$AIC)
# bic_values <- sapply(results, function(x) x$BIC)
#
# best_model_AIC <- results[[which.min(aic_values)]]$model
# best_model_BIC <- results[[which.min(bic_values)]]$model
#
#
# save(best_model_AIC,file="best_model_AIC.RData")
# save(best_model_BIC,file="best_model_BIC.RData")
load("best_model_AIC.RData")
load("best_model_BIC.RData")
# coef(final_lasso_cox)
# coef(scad_cox_path, lambda = best_lambda_scad)
# best_model_AIC |> coef()
# best_model_BIC |> coef()
coef_lasso <- as.vector(coef(final_lasso_cox))
names(coef_lasso) <- rownames(coef(final_lasso_cox))  # Set rownames explicitly for the LASSO coefficients
coef_scad_matrix <- coef(scad_cox_path, lambda = best_lambda_scad)
if (is.matrix(coef_scad_matrix)) {
coef_scad <- as.vector(coef_scad_matrix)
names(coef_scad) <- rownames(coef_scad_matrix)
} else {
coef_scad <- coef_scad_matrix
}
coef_aic <- coef(best_model_AIC)
coef_bic <- coef(best_model_BIC)
var_names <- unique(c(names(coef_lasso), names(coef_scad), names(coef_aic), names(coef_bic)))
coef_table <- data.frame(
Method = var_names,
LASSO = rep("-", length(var_names)),
SCAD = rep("-", length(var_names)),
AIC = rep("-", length(var_names)),
BIC = rep("-", length(var_names)),
stringsAsFactors = FALSE
)
rownames(coef_table) <- coef_table$Method
coef_table$Method <- NULL
for (var in var_names) {
if (var %in% names(coef_lasso)) {
coef_table[var, "LASSO"] <- sprintf("%.4f", coef_lasso[var])
}
if (var %in% names(coef_scad)) {
coef_table[var, "SCAD"] <- sprintf("%.4f", coef_scad[var])
}
if (var %in% names(coef_aic)) {
coef_table[var, "AIC"] <- sprintf("%.4f", coef_aic[var])
}
if (var %in% names(coef_bic)) {
coef_table[var, "BIC"] <- sprintf("%.4f", coef_bic[var])
}
}
coef_table[] <- lapply(coef_table, function(col) {
ifelse(col == "0.0000", "-", col)
})
coef_table <- coef_table[order(rowSums(coef_table != "-"), decreasing = TRUE), ]
kable(coef_table,caption = "Coefficient Estimates with Various Estimation Methods")
